### Parameter Estimation (Calibration): Yule-Walker Equations
1. What is parameter estimation: 
	- Assume we know the best values for $p$ and $q$ for a ARMA(p,q) process, to find the best values for the model parameters $(\phi_1, \phi_2,...,\phi_p, \theta_1,\theta_2,...,\theta_q)$ is what we called _parameter estimation_. 
		- MLE
		- Yule-Walker equations
		
2. Yule-Walker Equations
	For AR(p) process with mean 0 (for simplicity only, actually the mean doesn't matter): p+1 parameters $$X_t-\phi_1X_{t-1}-\phi_2X_{t-2}-...-\phi_pX_{t-p}=Z_t$$

	- Multiply both sides by $X_{t-j}$ and take the expectation, for each $j = 0,1,2,...,p$, we get p+1 equations: $$E[X_tX_{t-j}-\phi_1X_{t-1}X_{t-j}-\phi_2X_{t-2}X_{t-j}-...-\phi_pX_{t-p}X_{t-j}]=E[Z_tX_{t-j}], ~ j\in\{0,1,2,...,p\}$$
	- the right-hand side: causal process, which can be written as $$E[Z_tX_{t-j}]=\sum_{i=0}^{\infty}\psi_iE[Z_tZ_{t-j-i}]=\begin{cases}\sigma^2\psi_0=\sigma^2&j=0\\0&j=1,2,...,p\end{cases}$$
	- thus we have the $p+1$ equations as follows:
		$$\begin{align*}j=0 & \gamma_X(0)-\phi_1\gamma_X(1)-\phi_2\gamma_X(2)-...-\phi_p\gamma_X(p)=\sigma^2\\ j=1 & \gamma_X(1)-\phi_1\gamma_X(0)-\phi_2\gamma_X(1)-...-\phi_p\gamma_X(p-1)=0\\ \vdots & \\ j=p & \gamma_X(p)-\phi_1\gamma_X(p-1)-\phi_2\gamma_X(p-2)-...-\phi_p\gamma_X(0)=0 \end{align*}$$ 
		or in matrix form: 
		$$\begin{align*}\gamma_X(0)-\phi_1\gamma_X(1)-\phi_2\gamma_X(2)-...-\phi_p\gamma_X(p)&=\sigma^2\\ \left[\array{\gamma_X(0)&\gamma_X(1)&\dotsb&\gamma_X(p-1)\\\gamma_X(1)&\gamma_X(0)&\dotsb&\gamma_X(p-2)\\ \vdots&\vdots&\ddots&\vdots\\\gamma_X(p-1)&\gamma_X(p-2)&\dotsb&\gamma_X(0)}\right]\left[\array{\phi_1\\\phi_2\\\vdots\\\phi_p}\right]&=\left[\array{\gamma_X(1)\\\gamma_X(2)\\\vdots\\\gamma_X(p)}\right]\end{align*}$$
	- The solution of $p+1$ unknowns:
		$$\begin{align*}\left[\array{\hat\phi_1\\\hat\phi_2\\\vdots\\\hat\phi_p}\right] &= \left[\array{\hat\gamma_X(0)&\hat\gamma_X(1)&\dotsb&\hat\gamma_X(p-1)\\\hat\gamma_X(1)&\hat\gamma_X(0)&\dotsb&\hat\gamma_X(p-2)\\ \vdots&\vdots&\ddots&\vdots\\\hat\gamma_X(p-1)&\hat\gamma_X(p-2)&\dotsb&\hat\gamma_X(0)}\right]^{-1}\left[\array{\hat\gamma_X(1)\\\hat\gamma_X(2)\\\vdots\\\hat\gamma_X(p)}\right] \\ \hat\sigma^2 &=\hat\gamma_X(0)-\hat\phi_1\gamma_X(1)-\hat\phi_2\hat\gamma_X(2)-...-\hat\phi_p\hat\gamma_X(p) \end{align*}$$
		-- this is the _Yule-Walker Equations for Parameter Estimation_

3. Limitations of Yule-Walker:  
	Everything except AR process, the corresponding Yule-Walker equations are nonlinear.
	So for the other processes, we use MLE.
	- e.g. MA(1): $X_t=Z_t+\theta{Z}_{t-1}, ~ Z_t\sim N(0,\sigma^2)$
		- multiply both sides by $X_{t-j}$ for $j=0,1$: 
			$$\begin{cases}\gamma_X(0)=E[Z_tX_t]+\theta E[Z_{t-1}X_t]\\\gamma_X(1)=E[Z_tX_{t-1}]+\theta E[Z_{t-1}X_{t-1}]\end{cases}$$
			$$\Rightarrow\begin{cases}\gamma_X(0)=\sigma^2+\theta^2\sigma^2\\\gamma_X(1)=\theta\sigma^2\end{cases}$$ 
			which is an non-linear system.
	So Yule-Walker equations are _impractical_ for MA(q) processes, hence for ARMA(p,q) with $q>0$. (use MLE)
		- MLE properties (compared with Y-W):
			- less estimation bias 
			- less estimation variance
			- can deal with MA(q) and ARMA(p,q)
			- but more computationally expensive


